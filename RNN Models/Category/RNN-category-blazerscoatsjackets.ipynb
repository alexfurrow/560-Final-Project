{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import nltk\n",
    "import re\n",
    "import csv\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>key_0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>product_id</th>\n",
       "      <th>final_list</th>\n",
       "      <th>product_color_id</th>\n",
       "      <th>attribute_name</th>\n",
       "      <th>attribute_value</th>\n",
       "      <th>accessory</th>\n",
       "      <th>blazerscoatsjackets</th>\n",
       "      <th>bottom</th>\n",
       "      <th>onepiece</th>\n",
       "      <th>shoe</th>\n",
       "      <th>sweater</th>\n",
       "      <th>sweatshirthoodie</th>\n",
       "      <th>top</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2419</td>\n",
       "      <td>44437</td>\n",
       "      <td>51473</td>\n",
       "      <td>01E607BHRQAJDZ76MJFN7RPRK1</td>\n",
       "      <td>['rost', 'belted', 'short', 'cinched', 'natura...</td>\n",
       "      <td>01E607BHSBCWH034NX5TMJH3Z7</td>\n",
       "      <td>category</td>\n",
       "      <td>bottom</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6498</td>\n",
       "      <td>104365</td>\n",
       "      <td>123804</td>\n",
       "      <td>01E6079QFKH4HPZFQ31T6WDRRX</td>\n",
       "      <td>['elsa', 'slim', 'jean', 'slim', 'knee', 'hem'...</td>\n",
       "      <td>01E6079QG5GTP5JYRCWGRWY4ZC</td>\n",
       "      <td>category</td>\n",
       "      <td>bottom</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5707</td>\n",
       "      <td>93240</td>\n",
       "      <td>110390</td>\n",
       "      <td>01E6079DG58YW9K78D57C6J2Y1</td>\n",
       "      <td>['ravine', 'cotton', 'midi', 'dress', 'puff', ...</td>\n",
       "      <td>01E6079DGRR4CHKCPKNY96G15P</td>\n",
       "      <td>category</td>\n",
       "      <td>onepiece</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2808</td>\n",
       "      <td>50512</td>\n",
       "      <td>58649</td>\n",
       "      <td>01E6078G3GRATF2C96VKYYWSGD</td>\n",
       "      <td>['high', 'waist', 'moto', 'legging', 'pintucke...</td>\n",
       "      <td>01E6078G42KZPG57NCP4YG1TBB</td>\n",
       "      <td>category</td>\n",
       "      <td>bottom</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6284</td>\n",
       "      <td>101553</td>\n",
       "      <td>120143</td>\n",
       "      <td>01E6076GTCE5P3VH76VWJH4MY9</td>\n",
       "      <td>['krissy', 'espadrille', 'flat', 'woven', 'esp...</td>\n",
       "      <td>01E6076GTY5Z31KAGGW9HSYRDN</td>\n",
       "      <td>category</td>\n",
       "      <td>shoe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   key_0  Unnamed: 0.1                  product_id  \\\n",
       "0        2419   44437         51473  01E607BHRQAJDZ76MJFN7RPRK1   \n",
       "1        6498  104365        123804  01E6079QFKH4HPZFQ31T6WDRRX   \n",
       "2        5707   93240        110390  01E6079DG58YW9K78D57C6J2Y1   \n",
       "3        2808   50512         58649  01E6078G3GRATF2C96VKYYWSGD   \n",
       "4        6284  101553        120143  01E6076GTCE5P3VH76VWJH4MY9   \n",
       "\n",
       "                                          final_list  \\\n",
       "0  ['rost', 'belted', 'short', 'cinched', 'natura...   \n",
       "1  ['elsa', 'slim', 'jean', 'slim', 'knee', 'hem'...   \n",
       "2  ['ravine', 'cotton', 'midi', 'dress', 'puff', ...   \n",
       "3  ['high', 'waist', 'moto', 'legging', 'pintucke...   \n",
       "4  ['krissy', 'espadrille', 'flat', 'woven', 'esp...   \n",
       "\n",
       "             product_color_id attribute_name attribute_value  accessory  \\\n",
       "0  01E607BHSBCWH034NX5TMJH3Z7       category          bottom          0   \n",
       "1  01E6079QG5GTP5JYRCWGRWY4ZC       category          bottom          0   \n",
       "2  01E6079DGRR4CHKCPKNY96G15P       category        onepiece          0   \n",
       "3  01E6078G42KZPG57NCP4YG1TBB       category          bottom          0   \n",
       "4  01E6076GTY5Z31KAGGW9HSYRDN       category            shoe          0   \n",
       "\n",
       "   blazerscoatsjackets  bottom  onepiece  shoe  sweater  sweatshirthoodie  top  \n",
       "0                    0       1         0     0        0                 0    0  \n",
       "1                    0       1         0     0        0                 0    0  \n",
       "2                    0       0         1     0        0                 0    0  \n",
       "3                    0       1         0     0        0                 0    0  \n",
       "4                    0       0         0     1        0                 0    0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/Users/rachel/Downloads/blazerscoatsjackets_NN.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "from numpy import array, argmax, asarray, zeros\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Your Feature Space and Target Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df[\"blazerscoatsjackets\"]\n",
    "docs = df[\"final_list\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Label Categorical Encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "labels = to_categorical(encoder.fit_transform(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_text(text):\n",
    "    # remove backslash-apostrophe \n",
    "    text = re.sub(\"/'\", \"\", text) \n",
    "    # remove everything except alphabets \n",
    "    text = re.sub(\"[^a-zA-Z]\",\" \",text) \n",
    "    # remove whitespaces \n",
    "    text = ' '.join(text.split()) \n",
    "    # convert text to lowercase \n",
    "    text = text.lower() \n",
    "    \n",
    "    return text\n",
    "docs = docs.apply(str)\n",
    "docs = docs.apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize the Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token=\"UNKNOWN_TOKEN\")\n",
    "tokenizer.fit_on_texts(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integer Encode Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integer_encode_documents(docs, tokenizer):\n",
    "    return tokenizer.texts_to_sequences(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Max Length Per Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "def get_max_token_length_per_doc(docs: List[List[str]])-> int:\n",
    "    return max(list(map(lambda x: len(x.split()), docs)))\n",
    "\n",
    "# get the max length in terms of token length\n",
    "max_length = get_max_token_length_per_doc(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "MAX_SEQUENCE_LENGTH = 300\n",
    "# integer encode the documents\n",
    "encoded_docs = integer_encode_documents(docs, tokenizer)\n",
    "# this is a list of lists, the numbers represent the index position of that word.\n",
    "# for instance, 33 means the 33rd word in the vocabulary\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=MAX_SEQUENCE_LENGTH, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3969,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3969, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_docs, labels, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras RNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = int(len(tokenizer.word_index) * 1.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in Glove Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "def load_glove_vectors():\n",
    "    embeddings_index = {}\n",
    "    with open('glove.6B.100d.txt') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = coefs\n",
    "    print('Loaded %s word vectors.' % len(embeddings_index))\n",
    "    return embeddings_index\n",
    "\n",
    "\n",
    "embeddings_index = load_glove_vectors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in the Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "embedding_matrix = zeros((VOCAB_SIZE, 100))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: # check that it is an actual word that we have embeddings for\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.recurrent import SimpleRNN\n",
    "from keras.layers import Flatten, Masking\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Embedding(VOCAB_SIZE, 100, weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH, trainable=False))\n",
    "model.add(Masking(mask_value=0.0)) # masking layer, masks any words that don't have an embedding as 0s.\n",
    "model.add(SimpleRNN(units=64, input_shape=(1, MAX_SEQUENCE_LENGTH)))\n",
    "model.add(Dense(32))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 300, 100)          728800    \n",
      "_________________________________________________________________\n",
      "masking_1 (Masking)          (None, 300, 100)          0         \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, 64)                10560     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 741,506\n",
      "Trainable params: 12,706\n",
      "Non-trainable params: 728,800\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "`pydot` failed to call GraphViz.Please install GraphViz (https://www.graphviz.org/) and ensure that its executables are in the $PATH.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pydot.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, prog, format, encoding)\u001b[0m\n\u001b[1;32m   1914\u001b[0m                 \u001b[0marguments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1915\u001b[0;31m                 \u001b[0mworking_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtmp_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1916\u001b[0m             )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pydot.py\u001b[0m in \u001b[0;36mcall_graphviz\u001b[0;34m(program, arguments, working_dir, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mstdout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m     )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[1;32m    799\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[1;32m    801\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1550\u001b[0m                             \u001b[0merr_msg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m': '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1551\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dot': 'dot'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# to check the pydot/graphviz installation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pydot.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, prog, format, encoding)\u001b[0m\n\u001b[1;32m   1921\u001b[0m                     prog=prog)\n\u001b[0;32m-> 1922\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1923\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] \"dot\" not found in path.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-6d65aab07dd1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# summarize the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'model.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mplot_model\u001b[0;34m(model, to_file, show_shapes, show_layer_names, rankdir, expand_nested, dpi)\u001b[0m\n\u001b[1;32m    238\u001b[0m     \"\"\"\n\u001b[1;32m    239\u001b[0m     dot = model_to_dot(model, show_shapes, show_layer_names, rankdir,\n\u001b[0;32m--> 240\u001b[0;31m                        expand_nested, dpi)\n\u001b[0m\u001b[1;32m    241\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextension\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mextension\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[0;34m(model, show_shapes, show_layer_names, rankdir, expand_nested, dpi, subgraph)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0m_check_pydot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msubgraph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mdot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dashed'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         raise OSError(\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0;34m'`pydot` failed to call GraphViz.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0;34m'Please install GraphViz (https://www.graphviz.org/) '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             'and ensure that its executables are in the $PATH.')\n",
      "\u001b[0;31mOSError\u001b[0m: `pydot` failed to call GraphViz.Please install GraphViz (https://www.graphviz.org/) and ensure that its executables are in the $PATH."
     ]
    }
   ],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# summarize the model\n",
    "print(model.summary())\n",
    "plot_model(model, to_file='model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.928949\n",
       "1    0.071051\n",
       "Name: blazerscoatsjackets, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"blazerscoatsjackets\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "3572/3572 [==============================] - 10s 3ms/step - loss: 0.2827 - accuracy: 0.9113\n",
      "Epoch 2/15\n",
      "3572/3572 [==============================] - 10s 3ms/step - loss: 0.1845 - accuracy: 0.9378\n",
      "Epoch 3/15\n",
      "3572/3572 [==============================] - 10s 3ms/step - loss: 0.1197 - accuracy: 0.9583\n",
      "Epoch 4/15\n",
      "3572/3572 [==============================] - 11s 3ms/step - loss: 0.0882 - accuracy: 0.9700\n",
      "Epoch 5/15\n",
      "3572/3572 [==============================] - 11s 3ms/step - loss: 0.0608 - accuracy: 0.9796\n",
      "Epoch 6/15\n",
      "3572/3572 [==============================] - 11s 3ms/step - loss: 0.0376 - accuracy: 0.9902\n",
      "Epoch 7/15\n",
      "3572/3572 [==============================] - 11s 3ms/step - loss: 0.0258 - accuracy: 0.9913\n",
      "Epoch 8/15\n",
      "3572/3572 [==============================] - 10s 3ms/step - loss: 0.0186 - accuracy: 0.9947\n",
      "Epoch 9/15\n",
      "3572/3572 [==============================] - 10s 3ms/step - loss: 0.0161 - accuracy: 0.9955\n",
      "Epoch 10/15\n",
      "3572/3572 [==============================] - 11s 3ms/step - loss: 0.0249 - accuracy: 0.9908\n",
      "Epoch 11/15\n",
      "3572/3572 [==============================] - 11s 3ms/step - loss: 0.0106 - accuracy: 0.9969\n",
      "Epoch 12/15\n",
      "3572/3572 [==============================] - 11s 3ms/step - loss: 0.0048 - accuracy: 0.9992\n",
      "Epoch 13/15\n",
      "3572/3572 [==============================] - 11s 3ms/step - loss: 0.0041 - accuracy: 0.9989\n",
      "Epoch 14/15\n",
      "3572/3572 [==============================] - 12s 3ms/step - loss: 0.0026 - accuracy: 0.9994\n",
      "Epoch 15/15\n",
      "3572/3572 [==============================] - 11s 3ms/step - loss: 0.0037 - accuracy: 0.9983\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x12324bb90>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(X_train, y_train, epochs=15, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "397/397 [==============================] - 0s 993us/step\n",
      "Accuracy: 94.962215\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_docs = [\n",
    "    \"With a flattering twisted front, this fitted sheath dress is made in a plush velvet fabric, engineered with super-stretch for supreme comfort and cut pile-up for a high-shine look. Crew neck. 3/4 sleeves. Invisible zip at back. Twisted detail at the waist. Unlined.\"\n",
    "]\n",
    "\n",
    "test_docs = list(\n",
    "    map(lambda doc: \" \".join([token.text for token in nlp(doc) if not token.is_stop]), test_docs))\n",
    "\n",
    "encoded_test_sample = integer_encode_documents(test_docs, tokenizer)\n",
    "padded_test_docs = pad_sequences(encoded_test_sample, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(padded_test_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model.predict_classes(padded_test_docs)\n",
    "encoder.inverse_transform(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try get all(test version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "full = pd.read_csv(\"/Users/rachel/Desktop/full_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>brand</th>\n",
       "      <th>mpn</th>\n",
       "      <th>product_full_name</th>\n",
       "      <th>description</th>\n",
       "      <th>brand_category</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>deleted_at</th>\n",
       "      <th>brand_canonical_url</th>\n",
       "      <th>details</th>\n",
       "      <th>labels</th>\n",
       "      <th>bc_product_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01DSE9TC2DQXDG6GWKW9NMJ416</td>\n",
       "      <td>Banana Republic</td>\n",
       "      <td>514683</td>\n",
       "      <td>Ankle-Strap Pump</td>\n",
       "      <td>A modern pump, in a rounded silhouette with an...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2019-11-11 22:37:15.719107+00</td>\n",
       "      <td>2019-12-19 20:40:30.786144+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://bananarepublic.gap.com/browse/product....</td>\n",
       "      <td>A modern pump, in a rounded silhouette with an...</td>\n",
       "      <td>{\"Needs Review\"}</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01DSE9SKM19XNA6SJP36JZC065</td>\n",
       "      <td>Banana Republic</td>\n",
       "      <td>526676</td>\n",
       "      <td>Petite Tie-Neck Top</td>\n",
       "      <td>Dress it down with jeans and sneakers or dress...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2019-11-11 22:36:50.682513+00</td>\n",
       "      <td>2019-12-19 20:40:30.786144+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://bananarepublic.gap.com/browse/product....</td>\n",
       "      <td>Dress it down with jeans and sneakers or dress...</td>\n",
       "      <td>{\"Needs Review\"}</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01DSJX8GD4DSAP76SPR85HRCMN</td>\n",
       "      <td>Loewe</td>\n",
       "      <td>4.001E+11</td>\n",
       "      <td>52MM Padded Leather Round Sunglasses</td>\n",
       "      <td>Padded leather covers classic round sunglasses.</td>\n",
       "      <td>JewelryAccessories/SunglassesReaders/RoundOval...</td>\n",
       "      <td>2019-11-13 17:33:59.581661+00</td>\n",
       "      <td>2019-12-19 20:40:30.786144+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.saksfifthavenue.com/loewe-52mm-pad...</td>\n",
       "      <td>100% UV protection Case and cleaning cloth inc...</td>\n",
       "      <td>{\"Needs Review\"}</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01DSJVKJNS6F4KQ1QM6YYK9AW2</td>\n",
       "      <td>Converse</td>\n",
       "      <td>4.00012E+11</td>\n",
       "      <td>Baby's &amp; Little Kid's All-Star Two-Tone Mid-To...</td>\n",
       "      <td>The iconic mid-top design gets an added dose o...</td>\n",
       "      <td>JustKids/Shoes/Baby024Months/BabyGirl,JustKids...</td>\n",
       "      <td>2019-11-13 17:05:05.203733+00</td>\n",
       "      <td>2019-12-19 20:40:30.786144+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.saksfifthavenue.com/converse-babys...</td>\n",
       "      <td>Canvas upper Round toe Lace-up vamp SmartFOAM ...</td>\n",
       "      <td>{\"Needs Review\"}</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01DSK15ZD4D5A0QXA8NSD25YXE</td>\n",
       "      <td>Alexander McQueen</td>\n",
       "      <td>4.00011E+11</td>\n",
       "      <td>64MM Rimless Sunglasses</td>\n",
       "      <td>Hexagonal shades offer a rimless view with int...</td>\n",
       "      <td>JewelryAccessories/SunglassesReaders/RoundOval</td>\n",
       "      <td>2019-11-13 18:42:30.941321+00</td>\n",
       "      <td>2019-12-19 20:40:30.786144+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.saksfifthavenue.com/alexander-mcqu...</td>\n",
       "      <td>100% UV protection Gradient lenses Adjustable ...</td>\n",
       "      <td>{\"Needs Review\"}</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   product_id              brand          mpn  \\\n",
       "0  01DSE9TC2DQXDG6GWKW9NMJ416    Banana Republic       514683   \n",
       "1  01DSE9SKM19XNA6SJP36JZC065    Banana Republic       526676   \n",
       "2  01DSJX8GD4DSAP76SPR85HRCMN              Loewe    4.001E+11   \n",
       "3  01DSJVKJNS6F4KQ1QM6YYK9AW2           Converse  4.00012E+11   \n",
       "4  01DSK15ZD4D5A0QXA8NSD25YXE  Alexander McQueen  4.00011E+11   \n",
       "\n",
       "                                   product_full_name  \\\n",
       "0                                   Ankle-Strap Pump   \n",
       "1                                Petite Tie-Neck Top   \n",
       "2               52MM Padded Leather Round Sunglasses   \n",
       "3  Baby's & Little Kid's All-Star Two-Tone Mid-To...   \n",
       "4                            64MM Rimless Sunglasses   \n",
       "\n",
       "                                         description  \\\n",
       "0  A modern pump, in a rounded silhouette with an...   \n",
       "1  Dress it down with jeans and sneakers or dress...   \n",
       "2    Padded leather covers classic round sunglasses.   \n",
       "3  The iconic mid-top design gets an added dose o...   \n",
       "4  Hexagonal shades offer a rimless view with int...   \n",
       "\n",
       "                                      brand_category  \\\n",
       "0                                            Unknown   \n",
       "1                                            Unknown   \n",
       "2  JewelryAccessories/SunglassesReaders/RoundOval...   \n",
       "3  JustKids/Shoes/Baby024Months/BabyGirl,JustKids...   \n",
       "4     JewelryAccessories/SunglassesReaders/RoundOval   \n",
       "\n",
       "                      created_at                     updated_at deleted_at  \\\n",
       "0  2019-11-11 22:37:15.719107+00  2019-12-19 20:40:30.786144+00        NaN   \n",
       "1  2019-11-11 22:36:50.682513+00  2019-12-19 20:40:30.786144+00        NaN   \n",
       "2  2019-11-13 17:33:59.581661+00  2019-12-19 20:40:30.786144+00        NaN   \n",
       "3  2019-11-13 17:05:05.203733+00  2019-12-19 20:40:30.786144+00        NaN   \n",
       "4  2019-11-13 18:42:30.941321+00  2019-12-19 20:40:30.786144+00        NaN   \n",
       "\n",
       "                                 brand_canonical_url  \\\n",
       "0  https://bananarepublic.gap.com/browse/product....   \n",
       "1  https://bananarepublic.gap.com/browse/product....   \n",
       "2  https://www.saksfifthavenue.com/loewe-52mm-pad...   \n",
       "3  https://www.saksfifthavenue.com/converse-babys...   \n",
       "4  https://www.saksfifthavenue.com/alexander-mcqu...   \n",
       "\n",
       "                                             details            labels  \\\n",
       "0  A modern pump, in a rounded silhouette with an...  {\"Needs Review\"}   \n",
       "1  Dress it down with jeans and sneakers or dress...  {\"Needs Review\"}   \n",
       "2  100% UV protection Case and cleaning cloth inc...  {\"Needs Review\"}   \n",
       "3  Canvas upper Round toe Lace-up vamp SmartFOAM ...  {\"Needs Review\"}   \n",
       "4  100% UV protection Gradient lenses Adjustable ...  {\"Needs Review\"}   \n",
       "\n",
       "   bc_product_id  \n",
       "0            NaN  \n",
       "1            NaN  \n",
       "2            NaN  \n",
       "3            NaN  \n",
       "4            NaN  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>brand</th>\n",
       "      <th>mpn</th>\n",
       "      <th>product_full_name</th>\n",
       "      <th>description</th>\n",
       "      <th>brand_category</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>deleted_at</th>\n",
       "      <th>brand_canonical_url</th>\n",
       "      <th>details</th>\n",
       "      <th>labels</th>\n",
       "      <th>bc_product_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01DSE9TC2DQXDG6GWKW9NMJ416</td>\n",
       "      <td>Banana Republic</td>\n",
       "      <td>514683</td>\n",
       "      <td>Ankle-Strap Pump</td>\n",
       "      <td>A modern pump, in a rounded silhouette with an...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2019-11-11 22:37:15.719107+00</td>\n",
       "      <td>2019-12-19 20:40:30.786144+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://bananarepublic.gap.com/browse/product....</td>\n",
       "      <td>A modern pump, in a rounded silhouette with an...</td>\n",
       "      <td>{\"Needs Review\"}</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01DSE9SKM19XNA6SJP36JZC065</td>\n",
       "      <td>Banana Republic</td>\n",
       "      <td>526676</td>\n",
       "      <td>Petite Tie-Neck Top</td>\n",
       "      <td>Dress it down with jeans and sneakers or dress...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2019-11-11 22:36:50.682513+00</td>\n",
       "      <td>2019-12-19 20:40:30.786144+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://bananarepublic.gap.com/browse/product....</td>\n",
       "      <td>Dress it down with jeans and sneakers or dress...</td>\n",
       "      <td>{\"Needs Review\"}</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01DSJX8GD4DSAP76SPR85HRCMN</td>\n",
       "      <td>Loewe</td>\n",
       "      <td>4.001E+11</td>\n",
       "      <td>52MM Padded Leather Round Sunglasses</td>\n",
       "      <td>Padded leather covers classic round sunglasses.</td>\n",
       "      <td>JewelryAccessories/SunglassesReaders/RoundOval...</td>\n",
       "      <td>2019-11-13 17:33:59.581661+00</td>\n",
       "      <td>2019-12-19 20:40:30.786144+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.saksfifthavenue.com/loewe-52mm-pad...</td>\n",
       "      <td>100% UV protection Case and cleaning cloth inc...</td>\n",
       "      <td>{\"Needs Review\"}</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01DSJVKJNS6F4KQ1QM6YYK9AW2</td>\n",
       "      <td>Converse</td>\n",
       "      <td>4.00012E+11</td>\n",
       "      <td>Baby's &amp; Little Kid's All-Star Two-Tone Mid-To...</td>\n",
       "      <td>The iconic mid-top design gets an added dose o...</td>\n",
       "      <td>JustKids/Shoes/Baby024Months/BabyGirl,JustKids...</td>\n",
       "      <td>2019-11-13 17:05:05.203733+00</td>\n",
       "      <td>2019-12-19 20:40:30.786144+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.saksfifthavenue.com/converse-babys...</td>\n",
       "      <td>Canvas upper Round toe Lace-up vamp SmartFOAM ...</td>\n",
       "      <td>{\"Needs Review\"}</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01DSK15ZD4D5A0QXA8NSD25YXE</td>\n",
       "      <td>Alexander McQueen</td>\n",
       "      <td>4.00011E+11</td>\n",
       "      <td>64MM Rimless Sunglasses</td>\n",
       "      <td>Hexagonal shades offer a rimless view with int...</td>\n",
       "      <td>JewelryAccessories/SunglassesReaders/RoundOval</td>\n",
       "      <td>2019-11-13 18:42:30.941321+00</td>\n",
       "      <td>2019-12-19 20:40:30.786144+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.saksfifthavenue.com/alexander-mcqu...</td>\n",
       "      <td>100% UV protection Gradient lenses Adjustable ...</td>\n",
       "      <td>{\"Needs Review\"}</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   product_id              brand          mpn  \\\n",
       "0  01DSE9TC2DQXDG6GWKW9NMJ416    Banana Republic       514683   \n",
       "1  01DSE9SKM19XNA6SJP36JZC065    Banana Republic       526676   \n",
       "2  01DSJX8GD4DSAP76SPR85HRCMN              Loewe    4.001E+11   \n",
       "3  01DSJVKJNS6F4KQ1QM6YYK9AW2           Converse  4.00012E+11   \n",
       "4  01DSK15ZD4D5A0QXA8NSD25YXE  Alexander McQueen  4.00011E+11   \n",
       "\n",
       "                                   product_full_name  \\\n",
       "0                                   Ankle-Strap Pump   \n",
       "1                                Petite Tie-Neck Top   \n",
       "2               52MM Padded Leather Round Sunglasses   \n",
       "3  Baby's & Little Kid's All-Star Two-Tone Mid-To...   \n",
       "4                            64MM Rimless Sunglasses   \n",
       "\n",
       "                                         description  \\\n",
       "0  A modern pump, in a rounded silhouette with an...   \n",
       "1  Dress it down with jeans and sneakers or dress...   \n",
       "2    Padded leather covers classic round sunglasses.   \n",
       "3  The iconic mid-top design gets an added dose o...   \n",
       "4  Hexagonal shades offer a rimless view with int...   \n",
       "\n",
       "                                      brand_category  \\\n",
       "0                                            Unknown   \n",
       "1                                            Unknown   \n",
       "2  JewelryAccessories/SunglassesReaders/RoundOval...   \n",
       "3  JustKids/Shoes/Baby024Months/BabyGirl,JustKids...   \n",
       "4     JewelryAccessories/SunglassesReaders/RoundOval   \n",
       "\n",
       "                      created_at                     updated_at deleted_at  \\\n",
       "0  2019-11-11 22:37:15.719107+00  2019-12-19 20:40:30.786144+00        NaN   \n",
       "1  2019-11-11 22:36:50.682513+00  2019-12-19 20:40:30.786144+00        NaN   \n",
       "2  2019-11-13 17:33:59.581661+00  2019-12-19 20:40:30.786144+00        NaN   \n",
       "3  2019-11-13 17:05:05.203733+00  2019-12-19 20:40:30.786144+00        NaN   \n",
       "4  2019-11-13 18:42:30.941321+00  2019-12-19 20:40:30.786144+00        NaN   \n",
       "\n",
       "                                 brand_canonical_url  \\\n",
       "0  https://bananarepublic.gap.com/browse/product....   \n",
       "1  https://bananarepublic.gap.com/browse/product....   \n",
       "2  https://www.saksfifthavenue.com/loewe-52mm-pad...   \n",
       "3  https://www.saksfifthavenue.com/converse-babys...   \n",
       "4  https://www.saksfifthavenue.com/alexander-mcqu...   \n",
       "\n",
       "                                             details            labels  \\\n",
       "0  A modern pump, in a rounded silhouette with an...  {\"Needs Review\"}   \n",
       "1  Dress it down with jeans and sneakers or dress...  {\"Needs Review\"}   \n",
       "2  100% UV protection Case and cleaning cloth inc...  {\"Needs Review\"}   \n",
       "3  Canvas upper Round toe Lace-up vamp SmartFOAM ...  {\"Needs Review\"}   \n",
       "4  100% UV protection Gradient lenses Adjustable ...  {\"Needs Review\"}   \n",
       "\n",
       "   bc_product_id  \n",
       "0            NaN  \n",
       "1            NaN  \n",
       "2            NaN  \n",
       "3            NaN  \n",
       "4            NaN  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt = full.iloc[0:20,]\n",
    "tt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfor count, i in enumerate(tt[\"description\"]):\\n    test_docs = i\\n    print(count)\\n    start = time.time()\\n    test_docs = list(\" \".join([token.text for token in nlp(test_docs) if not token.is_stop]))\\n    #test_docs = list(\\n    #    map(lambda doc: \" \".join([token.text for token in nlp(doc) if not token.is_stop]), test_docs))\\n    #print([char for char in test_docs])\\n    #end = time.time()\\n    #print(end - start)\\n    #print(test_docs)\\n    encoded_test_sample = integer_encode_documents(test_docs, tokenizer)\\n    padded_test_docs = pad_sequences(encoded_test_sample, maxlen=MAX_SEQUENCE_LENGTH, padding=\\'post\\')\\n    #print(padded_test_docs)\\n    #print(count, \"before predict\")\\n    print(model.predict_classes(padded_test_docs))\\n    #print(count, \"after predict\")\\n    prediction = model.predict_classes(padded_test_docs)\\n    m = encoder.inverse_transform(prediction)\\n    new_list.append(m)\\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_list = []\n",
    "import time\n",
    "test_docs = []\n",
    "for i in tt[\"description\"]:\n",
    "    test_docs.append(i)\n",
    "test_docs = list(map(lambda doc: \" \".join([token.text for token in nlp(doc) if not token.is_stop]), test_docs))\n",
    "\n",
    "encoded_test_sample = integer_encode_documents(test_docs, tokenizer)\n",
    "padded_test_docs = pad_sequences(encoded_test_sample, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
    "\n",
    "print(model.predict_classes(padded_test_docs))\n",
    "'''\n",
    "for count, i in enumerate(tt[\"description\"]):\n",
    "    test_docs = i\n",
    "    print(count)\n",
    "    start = time.time()\n",
    "    test_docs = list(\" \".join([token.text for token in nlp(test_docs) if not token.is_stop]))\n",
    "    #test_docs = list(\n",
    "    #    map(lambda doc: \" \".join([token.text for token in nlp(doc) if not token.is_stop]), test_docs))\n",
    "    #print([char for char in test_docs])\n",
    "    #end = time.time()\n",
    "    #print(end - start)\n",
    "    #print(test_docs)\n",
    "    encoded_test_sample = integer_encode_documents(test_docs, tokenizer)\n",
    "    padded_test_docs = pad_sequences(encoded_test_sample, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
    "    #print(padded_test_docs)\n",
    "    #print(count, \"before predict\")\n",
    "    print(model.predict_classes(padded_test_docs))\n",
    "    #print(count, \"after predict\")\n",
    "    prediction = model.predict_classes(padded_test_docs)\n",
    "    m = encoder.inverse_transform(prediction)\n",
    "    new_list.append(m)\n",
    "'''\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
